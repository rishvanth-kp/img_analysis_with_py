{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Chapter 5: Image segmentation'\n",
        "jupyter: python3\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true\n",
        "  pdf:\n",
        "    documentclass: article\n",
        "    toc: true\n",
        "    fontsize: 12pt\n",
        "    geometry:\n",
        "      - top=1in\n",
        "      - bottom=1in\n",
        "      - left=1in\n",
        "      - right=1in\n",
        "      - heightrounded\n",
        "---\n",
        "\n",
        "\n",
        "# Introduction\n",
        "After we have a binary mask with all the desired objects in the foreground, the\n",
        "next step is to label each individual object with a unique ID. A segmentation\n",
        "algorithm typically takes as an input image (can be binary or grayscale, but we\n",
        "will focus on binary) and partitions it into distinct objects each with a\n",
        "different id.  A segmentation algorithm does not modify the input image, but\n",
        "generates a separate image with the object IDs. This image is called the label\n",
        "image, and is of the same size as the input image. Each pixels in the image is\n",
        "an number uniquely representing an object in the input image. This labels image\n",
        "can then the used together with the input image to extract the desired\n",
        "information about each object. \n",
        "\n",
        "\n",
        "\n",
        "# Connected components segmentation\n",
        "\n",
        "Connected components segmentation labels each of the connected (touching)\n",
        "foreground pixels as an object, i.e an object is entirely surrounded by\n",
        "background pixels. This segmentation is most useful then the object or sparse\n",
        "and not touching one another. If there are touching objects they will not be\n",
        "separated and get labeled with the same ID. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the required libraries\n",
        "import skimage as ski\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "# Load the cell images\n",
        "img = ski.io.imread(\"data/F01_202w2.TIF\")\n",
        "\n",
        "\n",
        "# Get the Triangle threshold\n",
        "binary_thresh = ski.filters.threshold_triangle(img)\n",
        "\n",
        "# Binary threshold the image\n",
        "img_binary = img > binary_thresh\n",
        "\n",
        "# Get the connected components segmentation\n",
        "label_img = ski.morphology.label(img_binary)\n",
        "# The number of segmented objects is the maximum value of the \n",
        "# label image\n",
        "print('Number of segmented objects = ' + str(label_img.max()))\n",
        "\n",
        "# Color the label image for visualization\n",
        "label_img_overlay = ski.color.label2rgb(label_img)\n",
        "\n",
        "# Plot the images\n",
        "fig, ax =  plt.subplots(2, 2)\n",
        "ax[0, 0].imshow(img, cmap = 'gray')\n",
        "ax[0, 0].set_title('Original image')\n",
        "ax[0, 1].imshow(img_binary, cmap = 'gray')\n",
        "ax[0, 1].set_title('Triangle threshold')\n",
        "ax[1, 0].imshow(label_img, cmap = 'gray')\n",
        "ax[1, 0].set_title('Label image')\n",
        "ax[1, 1].imshow(label_img_overlay)\n",
        "ax[1, 1].set_title('Colored label image')\n",
        "for a in ax.flatten():\n",
        "    a.set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The label image typically contains a 0 for the background as well, i.e the\n",
        "pixels that do not correspond to any object. As can the seen in the grayscale\n",
        "image, each objects starting from the top right get labeled with a distinct\n",
        "integer (thus represented as a shade of gray). The labels images are often\n",
        "overlaid with the original image and/or pseudo-colored for better visualization\n",
        "of the segmented objects. \n",
        "\n",
        "\n",
        "\n",
        "# Watershed segmentation\n",
        "\n",
        "Watershed segmentation is a way to segment objects when they are touching one\n",
        "another.  Watershed segments a grayscale image by treating the intensity of the\n",
        "image as the height of a dam. Think of the bright regions of the image as\n",
        "tall structures and dimmer regions as shorter structures. Watershed\n",
        "segmentation starts flooding the image from the lowest regions (or regions\n",
        "specified by the user), and when the water overflows into across a structure, a\n",
        "segmentation boundary is created. Since we need the segmentation boundaries at\n",
        "the object borders, the input image to watershed should be an image that has\n",
        "largest intensity values the object boundaries and the smallest values at the\n",
        "innermost regions of the cells.\n",
        "\n",
        "## Distance transform\n",
        "One way to get such an image from a binary image is to take a distance\n",
        "transform.  For each foreground pixel, the distance transform calculates the\n",
        "euclidean distance to the closest background pixel.  So the pixels that are\n",
        "just adjacent to the background are going to get a value of 1, and the pixels\n",
        "at the center of objects are going to get the highest value (the radius for a\n",
        "perfectly circular object). \n",
        "\n",
        "For watershed segmentation we need the center of objects to have the lowest\n",
        "value and the boundaries of the objects to have the largest values, we can get\n",
        "such an image by simply inverting the distance transformed image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the distance transform\n",
        "# Returns a float image, but let's not get into the details here\n",
        "img_dist = ndi.distance_transform_edt(img_binary)\n",
        "\n",
        "# Invert the distance\n",
        "img_dist_invert = ski.util.invert(img_dist)\n",
        "\n",
        "# Plot the images\n",
        "fig, ax =  plt.subplots(1, 3, figsize = (10, 4))\n",
        "ax[0].imshow(img, cmap = 'gray')\n",
        "ax[0].set_title('Original image')\n",
        "ax[1].imshow(img_dist, cmap = 'gray')\n",
        "ax[1].set_title('Distance transform')\n",
        "ax[2].imshow(img_dist_invert, cmap = 'gray')\n",
        "ax[2].set_title('Inverse of distance transform')\n",
        "for a in ax:\n",
        "    a.set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image maxima and minima\n",
        "Furthermore, we can also provide marker (seed) points to watershed\n",
        "segmentation. These marker regions are where the folding starts from. From our\n",
        "distance image, the ideal seed points would be the locations that are at the\n",
        "center of the objects, i.e with the smallest distance. These regions with the\n",
        "smallest values are surrounded by regions of higher values, i.e they are the\n",
        "minima intensity regions in an image. They can be detected with the h-minima\n",
        "algorithm. The h here refer to the minimum height to retain in the output.\n",
        "Smaller value of h will retain more minima and larger ones will will retain few\n",
        "ones. Therefore, the higher the h, just the larger objects that have a radial\n",
        "distance more than h will be retained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the h-minima for different values of h\n",
        "local_min_h2 = ski.morphology.h_minima(img_dist_invert, h = 2)\n",
        "local_min_h5 = ski.morphology.h_minima(img_dist_invert, h = 5)\n",
        "local_min_h25 = ski.morphology.h_minima(img_dist_invert, h = 25)\n",
        "\n",
        "# The h-minima are 1-pixel each. \n",
        "# Just making them bigger for visualization by dilation \n",
        "se = ski.morphology.ellipse(5, 5)\n",
        "local_min_h2_big = ski.morphology.binary_dilation(local_min_h2, se)\n",
        "local_min_h5_big = ski.morphology.binary_dilation(local_min_h5, se)\n",
        "local_min_h25_big = ski.morphology.binary_dilation(local_min_h25, se)\n",
        "\n",
        "# Plot the images\n",
        "fig, ax =  plt.subplots(2, 2)\n",
        "ax[0, 0].imshow(img_dist_invert, cmap = 'gray')\n",
        "ax[0, 0].set_title('Original Image')\n",
        "ax[0, 1].imshow(local_min_h2_big, cmap = 'gray')\n",
        "ax[0, 1].set_title('h-minima (h = 2)')\n",
        "ax[1, 0].imshow(local_min_h5_big, cmap = 'gray')\n",
        "ax[1, 0].set_title('h-minima (h = 5)')\n",
        "ax[1, 1].imshow(local_min_h25_big, cmap = 'gray')\n",
        "ax[1, 1].set_title('h-minima (h = 25)')\n",
        "for a in ax.flatten():\n",
        "    a.set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the distance transformed image and the h-minima image, we can\n",
        "use these for the watershed segmentation. Notice that the touching nucleii are\n",
        "separated out. The compactness parameter to watershed segmentation is used\n",
        "to adjust the smoothness in segmentation boundaries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The marker seeds need to be labels with a unique id.\n",
        "# We can get the connected components of the h-minima to label it\n",
        "nuc_seed_label = ski.morphology.label(local_min_h2)\n",
        "\n",
        "# Watershed segmentation\n",
        "label_img = ski.segmentation.watershed(img_dist_invert, \n",
        "                markers = nuc_seed_label, mask = img_binary, compactness = 0)\n",
        "print('Number of segmented objects = ' + str(label_img.max()))\n",
        "\n",
        "# Color the label image for visualization\n",
        "label_img_overlay = ski.color.label2rgb(label_img)\n",
        "\n",
        "# Write the manipulated image to file\n",
        "ski.io.imsave('data/out.tif', label_img_overlay, check_contrast = False)\n",
        "\n",
        "# Plot the images\n",
        "fig, ax =  plt.subplots(2, 2)\n",
        "ax[0, 0].imshow(img_dist, cmap = 'gray')\n",
        "ax[0, 0].set_title('Distance transform')\n",
        "ax[0, 1].imshow(local_min_h2_big, cmap = 'gray')\n",
        "ax[0, 1].set_title('Watershed markers (seeds)')\n",
        "ax[1, 0].imshow(label_img, cmap = 'gray')\n",
        "ax[1, 0].set_title('Watershed label image')\n",
        "ax[1, 1].imshow(label_img_overlay)\n",
        "ax[1, 1].set_title('Colored label image')\n",
        "for a in ax.flatten():\n",
        "    a.set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/rish/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}